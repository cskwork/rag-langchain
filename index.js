#!/usr/bin/env node

import { RAGSystem } from './src/rag.js';
import { validateEnvironment, handleError } from './src/utils/helpers.js';
import { startInteractiveChat } from './src/interactive-chat.js';
import { CONFIG } from './src/config.js';

// ì „ì—­ RAG ì‹œìŠ¤í…œ ì¸ìŠ¤í„´ìŠ¤
let ragSystem = null;

/**
 * í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ ì‹œ ì •ë¦¬ ì‘ì—…
 * (Cleanup on process exit)
 */
const cleanup = async () => {
  if (ragSystem) {
    console.log('\nğŸ›‘ Shutting down gracefully...');
    ragSystem = null;
  }
  process.exit(0);
};

// í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ ë“±ë¡
process.on('SIGINT', cleanup);
process.on('SIGTERM', cleanup);
process.on('uncaughtException', async (error) => {
  console.error('ğŸ’¥ Uncaught Exception:', error);
  await cleanup();
});
process.on('unhandledRejection', async (reason, promise) => {
  console.error('ğŸ’¥ Unhandled Rejection at:', promise, 'reason:', reason);
  await cleanup();
});

/**
 * ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
 * (Main execution function)
 */
async function main() {
  // ëª…ë ¹ì¤„ ì¸ìˆ˜ íŒŒì‹± (Parse command line arguments)
  const args = process.argv.slice(2);
  const isInteractive = args.includes('--interactive') || args.includes('-i');
  const isStreamingMode = args.includes('--streaming') || args.includes('-s');
  const isHelp = args.includes('--help') || args.includes('-h');
  
  // ë„ì›€ë§ í‘œì‹œ (Show help)
  if (isHelp) {
    showHelp();
    return;
  }
  
  console.log('ğŸ¤– RAG LangChain Application with OpenRouter');
  console.log('=' .repeat(50));
  
  // ëŒ€í™”í˜• ëª¨ë“œ (Interactive mode)
  if (isInteractive) {
    console.log('ğŸ—£ï¸  Starting interactive chat mode...');
    console.log('ğŸ’¡ Use --help for more options');
    
    try {
      await startInteractiveChat();
    } catch (error) {
      handleError(error, 'interactive chat');
      process.exit(1);
    }
    return;
  }
  
  // ìƒ˜í”Œ ëª¨ë“œ (Sample mode)
  try {
    // í™˜ê²½ ë³€ìˆ˜ ê²€ì¦ (Validate environment)
    validateEnvironment();
    
    // RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” (Initialize RAG system)
    ragSystem = new RAGSystem();
    await ragSystem.initialize();
    
    // ìƒíƒœ í™•ì¸ (Check status)
    const status = ragSystem.getStatus();
    console.log('\nğŸ“Š System Status:');
    console.log(`   - Has Embeddings: ${status.hasEmbeddings}`);
    console.log(`   - LLM Model: ${status.model}`);
    console.log(`   - Embedding Model: ${status.embeddingModel}`);
    console.log(`   - Has Conversational Graph: ${status.hasConversationalGraph}`);
    console.log(`   - Tools Enabled: ${CONFIG.TOOLS.ENABLED}`);
    
    // ë¬¸ì„œ ì¸ë±ì‹± (Build index)
    console.log('\nğŸ“š Building document index...');
    const indexInfo = await ragSystem.buildIndex();
    console.log(`   - Documents loaded: ${indexInfo.documentsLoaded}`);
    console.log(`   - Chunks created: ${indexInfo.chunksCreated}`);
    console.log(`   - Vector store size: ${indexInfo.vectorStoreSize}`);
    
    // ìƒ˜í”Œ ì§ˆë¬¸ë“¤ (Sample questions)
    const sampleQuestions = [
      "What is task decomposition?",
      "What are the challenges in LLM-powered autonomous agents?",
      "How does Chain of Thought (CoT) prompting work?",
      "What is the difference between ReAct and Reflexion?"
    ];
    
    console.log('\nğŸ¯ Testing with sample questions...');
    console.log('=' .repeat(50));
    
    // ê° ì§ˆë¬¸ì— ëŒ€í•´ ë‹µë³€ ìƒì„± (Generate answers for each question)
    for (let i = 0; i < sampleQuestions.length; i++) {
      const question = sampleQuestions[i];
      
      console.log(`\n[${i + 1}/${sampleQuestions.length}]`);
      
      try {
        if (isStreamingMode) {
          // ìŠ¤íŠ¸ë¦¬ë° ë‹µë³€ í™œì„±í™” (Streaming answer generation)
          console.log(`\nâ“ Question: ${question}`);
          console.log('ğŸŒŠ Streaming answer:');
          console.log('-'.repeat(50));
          
          let answerText = '';
          for await (const chunk of ragSystem.generateAnswerStream(question)) {
            // ìŠ¤íŠ¸ë¦¬ë° ì²­í¬ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ì¶œë ¥ (Real-time streaming chunk output)
            process.stdout.write(chunk);
            answerText += chunk;
          }
          
          console.log('\n' + '-'.repeat(50));
          console.log('âœ… Answer completed');
        } else {
          // ë„êµ¬ í™œì„±í™” ì—¬ë¶€ì— ë”°ë¥¸ ë‹µë³€ ìƒì„± (Answer generation based on tool enablement)
          if (CONFIG.TOOLS.ENABLED) {
            const result = await ragSystem.generateAnswerWithTools(question);
            console.log(`\nâ“ Question: ${question}`);
            console.log(`\nğŸ¤– Answer: ${result.answer}`);
            if (result.usedTools && result.toolResults.length > 0) {
              console.log(`\nğŸ”§ Tools used: ${result.toolResults.length} tool(s)`);
            }
          } else {
            // ì¼ë°˜ ë‹µë³€ ìƒì„± (Regular answer generation)
            await ragSystem.generateAnswer(question);
          }
        }
        
      } catch (error) {
        handleError(error, `question ${i + 1}`);
        continue;
      }
      
      // ì§ˆë¬¸ ê°„ ê°„ê²© (Spacing between questions)
      if (i < sampleQuestions.length - 1) {
        console.log('\n' + '-'.repeat(30));
      }
    }
    
    console.log('\nâœ… All questions processed successfully!');
    
    // ìµœì¢… ì‹œìŠ¤í…œ ìƒíƒœ ì¶œë ¥
    const finalStatus = ragSystem.getStatus();
    console.log('\nğŸ“Š Final System Status:');
    console.log(`   - Has Vector Store: ${finalStatus.hasVectorStore}`);
    console.log(`   - Has Graph: ${finalStatus.hasGraph}`);
    console.log(`   - Has Conversational Graph: ${finalStatus.hasConversationalGraph}`);
    console.log(`   - Model: ${finalStatus.model}`);
    
    // ì‚¬ìš©ë²• íŒíŠ¸ (Usage hints)
    console.log('\nğŸ’¡ Usage:');
    console.log('   - Interactive mode: node index.js --interactive');
    console.log('   - Streaming mode: node index.js --streaming');
    console.log('   - Regular mode: node index.js (default)');
    
  } catch (error) {
    handleError(error, 'main execution');
    process.exit(1);
  } finally {
    // ì •ë¦¬ ì‘ì—… ìˆ˜í–‰
    if (ragSystem) {
      await ragSystem.cleanup();
      ragSystem = null;
    }
  }
}

/**
 * ë„ì›€ë§ í‘œì‹œ í•¨ìˆ˜
 * (Show help function)
 */
function showHelp() {
  console.log(`
ğŸ¤– RAG LangChain Application with OpenRouter
===========================================

Usage:
  node index.js [options]

Options:
  -i, --interactive    Start interactive chat mode
  -s, --streaming      Enable streaming mode for sample questions
  -h, --help          Show this help message

Examples:
  node index.js                    # Run sample questions (default)
  node index.js --interactive      # Start interactive chat
  node index.js --streaming        # Run sample questions with streaming
  node index.js -i                 # Short form for interactive mode

Environment Variables:
  OPENROUTER_API_KEY              # Required: OpenRouter API key
  OPENAI_API_KEY                  # Required: OpenAI API key for embeddings
  LLM_MODEL                       # Optional: LLM model to use
  EMBEDDING_MODEL                 # Optional: Embedding model to use
  CHROMA_COLLECTION_NAME          # Optional: Chroma collection name
  CHROMA_PERSIST_DIR              # Optional: Chroma persistence directory

For more information, see the README.md file.
`);
}

// ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ (Script execution)
if (import.meta.url === `file://${process.argv[1]}`) {
  main().catch(error => {
    console.error('ğŸ’¥ Unhandled error:', error);
    process.exit(1);
  });
} 