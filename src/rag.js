import { CheerioWebBaseLoader } from "@langchain/community/document_loaders/web/cheerio";
import { RecursiveCharacterTextSplitter } from "langchain/text_splitter";
import { MemoryVectorStore } from "langchain/vectorstores/memory";
import { StateGraph, START, END } from "@langchain/langgraph";
import { EmbeddingsOpenAI } from './wrappers/embeddings-openai.js';
import { CONFIG } from './config.js';

/**
 * RAG ì‹œìŠ¤í…œ í´ë˜ìŠ¤ - StateGraph ì‚¬ìš©
 * (RAG System Class with StateGraph)
 */
export class RAGSystem {
  constructor() {
    this.vectorStore = null;
    this.embeddings = null;
    this.graph = null;
  }

  /**
   * RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
   * (Initialize RAG system)
   */
  async initialize() {
    try {
      console.log('ğŸš€ Initializing RAG system...');
      
      // OpenRouter API í‚¤ ê²€ì¦
      if (!CONFIG.OPENROUTER.API_KEY || !CONFIG.OPENROUTER.LLM_MODEL) {
        throw new Error('OpenRouter API key and model are required');
      }

      // ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
      this.embeddings = EmbeddingsOpenAI({
        modelName: CONFIG.OPENAI.EMBEDDING_MODEL,
        apiKey: CONFIG.OPENAI.API_KEY
      });

      console.log('âœ… RAG system initialized successfully');
      
    } catch (error) {
      console.error('âŒ RAG initialization failed:', error.message);
      throw error;
    }
  }

  /**
   * ë¬¸ì„œ ë¡œë“œ ë° ì¸ë±ì‹±
   * (Load and index documents)
   */
  async buildIndex(documentUrl = CONFIG.DEFAULT_DOCUMENT_URL) {
    if (!this.embeddings) {
      throw new Error('RAG system not initialized. Call initialize() first.');
    }

    try {
      console.log('ğŸ“„ Loading documents...');
      
      // 1. ë¬¸ì„œ ë¡œë“œ
      const loader = new CheerioWebBaseLoader(documentUrl);
      const docs = await loader.load();
      console.log(`ğŸ“„ Loaded ${docs.length} document(s)`);

      // 2. í…ìŠ¤íŠ¸ ë¶„í• 
      const textSplitter = new RecursiveCharacterTextSplitter({
        chunkSize: CONFIG.TEXT_SPLITTER.CHUNK_SIZE,
        chunkOverlap: CONFIG.TEXT_SPLITTER.CHUNK_OVERLAP,
        separators: CONFIG.TEXT_SPLITTER.SEPARATORS
      });
      const splitDocs = await textSplitter.splitDocuments(docs);
      console.log(`ğŸ“ Split into ${splitDocs.length} chunks`);

      // 3. ë²¡í„° ìŠ¤í† ì–´ ìƒì„± ë° ë¬¸ì„œ ì €ì¥
      this.vectorStore = new MemoryVectorStore(this.embeddings);
      await this.vectorStore.addDocuments(splitDocs);
      console.log('ğŸ’¾ Documents embedded and stored in vector store');

      // 4. StateGraph ì›Œí¬í”Œë¡œìš° ìƒì„±
      this._createStateGraph();

      return {
        documentsLoaded: docs.length,
        chunksCreated: splitDocs.length,
        vectorStoreSize: splitDocs.length
      };
    } catch (error) {
      console.error('âŒ Index building failed:', error.message);
      throw error;
    }
  }

  /**
   * StateGraph ì›Œí¬í”Œë¡œìš° ìƒì„±
   * (Create StateGraph workflow)
   */
  _createStateGraph() {
    // ìƒíƒœ ì •ì˜
    const workflow = new StateGraph({
      channels: {
        question: null,
        context: null,
        answer: null
      }
    });

    // ë¬¸ì„œ ê²€ìƒ‰ ë…¸ë“œ
    const retrieveNode = async (state) => {
      console.log(`ğŸ” Retrieving documents for: ${state.question}`);
      
      const docs = await this.vectorStore.similaritySearch(
        state.question,
        CONFIG.RETRIEVAL.TOP_K
      );
      
      const context = docs.map(doc => doc.pageContent).join('\n\n');
      console.log(`ğŸ“š Retrieved ${docs.length} relevant documents`);
      
      return { context };
    };

    // ë‹µë³€ ìƒì„± ë…¸ë“œ
    const generateNode = async (state) => {
      console.log('ğŸ¤– Generating answer...');
      
      const prompt = `Use the following pieces of context to answer the question at the end.
If you don't know the answer, just say that you don't know, don't try to make up an answer.
Use three sentences maximum and keep the answer as concise as possible.

Context: ${state.context}

Question: ${state.question}

Helpful Answer:`;

      const headers = {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${CONFIG.OPENROUTER.API_KEY}`,
      };

      const requestBody = {
        model: CONFIG.OPENROUTER.LLM_MODEL,
        messages: [{ role: 'user', content: prompt }],
        temperature: CONFIG.LLM.TEMPERATURE,
        max_tokens: CONFIG.LLM.MAX_TOKENS,
        top_p: CONFIG.LLM.TOP_P,
      };

      const response = await fetch('https://openrouter.ai/api/v1/chat/completions', {
        method: 'POST',
        headers,
        body: JSON.stringify(requestBody),
      });

      if (!response.ok) {
        const errorText = await response.text();
        throw new Error(`OpenRouter API Error (${response.status}): ${errorText}`);
      }

      const data = await response.json();
      const answer = data.choices[0].message.content;
      
      return { answer };
    };

    // ë…¸ë“œ ì¶”ê°€
    workflow.addNode("retrieve", retrieveNode);
    workflow.addNode("generate", generateNode);

    // ì—£ì§€ ì¶”ê°€
    workflow.addEdge(START, "retrieve");
    workflow.addEdge("retrieve", "generate");
    workflow.addEdge("generate", END);

    // ê·¸ë˜í”„ ì»´íŒŒì¼
    this.graph = workflow.compile();
  }

  /**
   * ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ìƒì„± (StateGraph ì‚¬ìš©)
   * (Generate answer for question using StateGraph)
   */
  async generateAnswer(question) {
    if (!this.graph) {
      throw new Error('StateGraph not initialized. Call buildIndex() first.');
    }

    try {
      console.log(`\nâ“ Question: ${question}`);
      
      // StateGraph ì‹¤í–‰
      const result = await this.graph.invoke({
        question: question
      });
      
      console.log(`\nğŸ’¬ Answer: ${result.answer}`);
      return result.answer;
      
    } catch (error) {
      console.error('âŒ Answer generation failed:', error.message);
      throw error;
    }
  }

  /**
   * ìŠ¤íŠ¸ë¦¬ë° ë‹µë³€ ìƒì„± (OpenRouter API ì§ì ‘ í˜¸ì¶œ)
   * (Generate streaming answer using direct OpenRouter API call)
   */
  async *generateAnswerStream(question) {
    if (!this.vectorStore) {
      throw new Error('Vector store not initialized. Call buildIndex() first.');
    }

    try {
      // 1. ë¬¸ì„œ ê²€ìƒ‰ (Document retrieval)
      console.log(`ğŸ” Retrieving documents for: ${question}`);
      const docs = await this.vectorStore.similaritySearch(
        question,
        CONFIG.RETRIEVAL.TOP_K
      );
      
      const context = docs.map(doc => doc.pageContent).join('\n\n');
      console.log(`ğŸ“š Retrieved ${docs.length} relevant documents`);
      
      // 2. í”„ë¡¬í”„íŠ¸ êµ¬ì„± (Construct prompt)
      const prompt = `Use the following pieces of context to answer the question at the end.
If you don't know the answer, just say that you don't know, don't try to make up an answer.
Use three sentences maximum and keep the answer as concise as possible.

Context: ${context}

Question: ${question}

Helpful Answer:`;

      // 3. ìŠ¤íŠ¸ë¦¬ë° API í˜¸ì¶œ (Streaming API call)
      console.log('ğŸ¤– Generating streaming answer...');
      
      const headers = {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${CONFIG.OPENROUTER.API_KEY}`,
      };

      const requestBody = {
        model: CONFIG.OPENROUTER.LLM_MODEL,
        messages: [{ role: 'user', content: prompt }],
        temperature: CONFIG.LLM.TEMPERATURE,
        max_tokens: CONFIG.LLM.MAX_TOKENS,
        top_p: CONFIG.LLM.TOP_P,
        stream: true // ìŠ¤íŠ¸ë¦¬ë° í™œì„±í™”
      };

      const response = await fetch('https://openrouter.ai/api/v1/chat/completions', {
        method: 'POST',
        headers,
        body: JSON.stringify(requestBody),
      });

      if (!response.ok) {
        const errorText = await response.text();
        throw new Error(`OpenRouter API Error (${response.status}): ${errorText}`);
      }

      // 4. ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²˜ë¦¬ (Process streaming response)
      const reader = response.body.getReader();
      const decoder = new TextDecoder();
      let buffer = '';

      while (true) {
        const { done, value } = await reader.read();
        if (done) break;

        buffer += decoder.decode(value, { stream: true });
        const lines = buffer.split('\n');
        buffer = lines.pop() || '';

        for (const line of lines) {
          const trimmed = line.trim();
          if (trimmed === '' || trimmed === 'data: [DONE]') continue;
          
          if (trimmed.startsWith('data: ')) {
            try {
              const data = JSON.parse(trimmed.slice(6));
              if (data.choices && data.choices[0] && data.choices[0].delta && data.choices[0].delta.content) {
                const content = data.choices[0].delta.content;
                yield content;
              }
            } catch (parseError) {
              // íŒŒì‹± ì˜¤ë¥˜ ë¬´ì‹œ (Ignore parsing errors)
              continue;
            }
          }
        }
      }
      
    } catch (error) {
      console.error('âŒ Streaming answer generation failed:', error.message);
      throw error;
    }
  }

  /**
   * ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸
   * (Check system status)
   */
  getStatus() {
    return {
      hasEmbeddings: !!this.embeddings,
      hasVectorStore: !!this.vectorStore,
      hasGraph: !!this.graph,
      model: CONFIG.OPENROUTER.LLM_MODEL,
      embeddingModel: CONFIG.OPENAI.EMBEDDING_MODEL
    };
  }
}